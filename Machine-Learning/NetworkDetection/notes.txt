Machine Learning 101


Machine learning is a field of computer science that uses statistical techniques to give computer systems the ability 
to “learn” (i.e., progressively improve performance on a specific task) with data, without being explicitly programmed.
Given a data set, learn a "model" from this data using learning algorithms. 
Once a "model" is learned, it can be used to make prediction to new input data.





Basic Terminology
We need to collect a data set before we start to do machine learning. Suppose we have a data set of facial images. The data set contains 1000 images, each with a label indicating whether the image contains a human face.

Sample: every image and it's corresponding label is a sample.

Feature: a feature is an individual measurable property or characteristic of a phenomenon being observed. A pixel value in face image is a feature.

Learning or Training: the process of generating a model from data.

Classification: If the label of samples are discrete values, such as "good" or "bad", then this learning task is called classification. If a model trained on a face image data set, it can predict whether a face is included in the image, then this model is a classification model.

Regression: If the label of samples are real values, then this learning task is called regression. If we are training a face detection model on a face data set, the task is to predict the face's bounding box, then this is a regression model. The reason is the prediction value includes the bounding box's coordinates and size, and the coordinates and size are continuous variables.

Clustering: If the label of samples are not provided, and the learning task is to assign the input data into one of several groups. In theory, data points that are in the same group should have similar features, while data points in different groups should have highly dissimilar features.

Supervised Learning: training using labeled examples, such as an input where the desired output is known. An example is comprised of n-dimensional features and a label, as illustrated in fig1.
The learning algorithm receives a set of inputs along with the corresponding correct outputs, and the algorithm learns by comparing its actual output with correct outputs to find errors. It then modifies the model accordingly. Through methods like classification, regression, prediction and gradient boosting, supervised learning uses patterns to predict the values of the label on additional unlabeled data. 
Supervised learning is commonly used in applications where historical data predicts likely future events. For example, it can anticipate when credit card transactions are likely to be fraudulent or which insurance customer is likely to file a claim.

Ex. [Feature 1][Feature 2]..[Feature N][Label]


Unsupervised learning: is used against data that has no historical labels. The system is not told the "right answer." The algorithm must figure out what is being shown. The goal is to explore the data and find some structure within. Unsupervised learning works well on transactional data. For example, it can identify segments of customers with similar attributes who can then be treated similarly in marketing campaigns. Or it can find the main attributes that separate customer segments from each other. Popular techniques include self-organizing maps, nearest-neighbor mapping, k-means clustering and singular value decomposition. These algorithms are also used to segment text topics, recommend items and identify data outliers.






Applications:

- Computer Vision: video stream, like people or vehicles. It can be used to build smart retail stores like Amazon Go. It also can used to build smart cities, it can help improve traffic, safety, etc. User experience.

- Computer Hearing {Speech Recognition}

There are still many other machine learning applications, including indoor location systems,
network threat prevention, recommendation systems and so on







Part 3: Introduction of Linear and Logistic Regression

Linear Regression
Linear regression is a statistical method that allows us to summarize and study relationships between features vector x and label y:

Given a sample x = (x1; x2; …; xn), xi is the i-th feature, the relationship between x and y can be formulated as Eq 1







Logistic Regression:

Logistic regression is a transformation of linear regression. Although it's name is logistic regression,
it is mainly used for classification problems, like the following examples:

To predict whether an email is spam(1) or not(0)
To predict if a stock price will increase(1) or decrease(0)
If we want to use linear regression to do a classification task, we need to set a threshold. If the prediction value is larger than the threshold, then the example will be classified as class 1, otherwise the example will be classified as class 2.

The prediction of linear regression can be infinite or negative infinite. In order to compress the prediction value
into range [0, 1], the sigmoid function is used to replace the linear function.









Part 4: Introduction of Machine Learning Tools
Scikit-learn
Scikit learning is an open sourced python package for machine learning, providing.

Simple and efficient tools for data mining and data analysis.
Tools for feature transformation, model selection, supervised learning,
unsupervised learning, model evaluation.


KDD Cup 99 data set
The KDD Cup 99 data set is used to build a network intrusion detector, a predictive model capable of
distinguish between “bad” connections, called intrusions or attacks, and “good” normal connections.
There are 494,021 examples in this data set, and each dataset is comprised of 41 features and 1 label.